{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Yc_QGcPrvhgj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from math import e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Zz81ZoDxvhgm"
      },
      "outputs": [],
      "source": [
        "def forward(W1, W2, b1, b2, x):\n",
        "    capa1 = W1 @ x + b1\n",
        "    \n",
        "    m = capa1.shape[0]\n",
        "    \n",
        "    for i in range(m):\n",
        "        capa1[i][0] = max(0, capa1[i][0])\n",
        "\n",
        "    capa2 = W2 @ capa1 + b2\n",
        "    return capa2[0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "wpp8zX0evhgn"
      },
      "outputs": [],
      "source": [
        "#Inicializacion de pesos\n",
        "\n",
        "W1 = np.random.random((5, 6))  # matriz 5x6 \n",
        "b1 = np.random.random((5, 1))\n",
        "\n",
        "W2 = np.random.random((1, 5))\n",
        "b2 = np.random.random((1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Calculo del gradiente numerico\n",
        "def funcion_objetivo(x, y, W1, W2, b1, b2):\n",
        "    loss = 0.5*((forward(W1,W2,b1,b2,x.transpose())-y)**2)\n",
        "    return loss\n",
        "\n",
        "def numerical_gradient(x, y, W1, W2, b1, b2, eps):\n",
        "    for i in range(W1.shape[0]):\n",
        "        for j in range(W1.shape[1]):\n",
        "            W1_izq = W1 \n",
        "            W1_izq[i][j] = W1_izq[i][j] + eps\n",
        "            W1_der = W1 \n",
        "            W1_der[i][j] = W1_der[i][j] - eps\n",
        "            izq_W1 = funcion_objetivo(x, y, W1_izq, W2, b1, b2)\n",
        "            der_W1 = funcion_objetivo(x, y, W1_der, W2, b1, b2)\n",
        "            derivada_W1 = (izq_W1 - der_W1)/(2*eps)\n",
        "    for i in range(W2.shape[0]):\n",
        "        for j in range(W2.shape[1]):\n",
        "            W2_izq = W2\n",
        "            W2_izq[i][j] = W2_izq[i][j] + eps\n",
        "            W2_der = W2\n",
        "            W2_der[i][j] = W2_der[i][j] - eps\n",
        "            izq_W2 = funcion_objetivo(x, y, W1, W2_izq, b1, b2)\n",
        "            der_W2 = funcion_objetivo(x, y, W1, W2_der, b1, b2)\n",
        "            derivada_W2 = (izq_W2 - der_W2)/(2*eps)\n",
        "    for i in range(b1.shape[0]):\n",
        "        for j in range(b1.shape[1]):\n",
        "            b1_izq = b1\n",
        "            b1_izq[i][j] = b1_izq[i][j] + eps\n",
        "            b1_der = b1\n",
        "            b1_der[i][j] = b1_der[i][j] - eps\n",
        "            izq_b1 = funcion_objetivo(x, y, W1, W2, b1_izq, b2)\n",
        "            der_b1 = funcion_objetivo(x, y, W1, W2, b1_der, b2)\n",
        "            derivada_b1 = (izq_b1 - der_b1)/(2*eps)\n",
        "    for i in range(b2.shape[0]):\n",
        "        for j in range(b2.shape[1]):\n",
        "            b2_izq = b2\n",
        "            b2_izq[i][j] = b2_izq[i][j] + eps\n",
        "            b2_der = b2\n",
        "            b2_der[i][j] = b2_der[i][j] - eps\n",
        "            izq_b2 = funcion_objetivo(x, y, W1, W2, b1, b2_der)\n",
        "            der_b2 = funcion_objetivo(x, y, W1, W2, b1, b2_izq)\n",
        "            derivada_b2 = (izq_b2 - der_b2)/(2*eps)\n",
        "    \n",
        "    gradiente = np.zeros((4,1))\n",
        "    gradiente[0][0] = derivada_W1\n",
        "    gradiente[1][0] = derivada_W2\n",
        "    gradiente[2][0] = derivada_b1\n",
        "    gradiente[3][0] = derivada_b2\n",
        "    \n",
        "    return gradiente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "P-R0FjEzvhgn"
      },
      "outputs": [],
      "source": [
        "# #Calculo del gradiente numerico\n",
        "# def funcion_objetivo(x, y, W1, W2, b1, b2):\n",
        "#     loss = 0.5*((forward(W1,W2,b1,b2,x.transpose())-y)**2)\n",
        "#     return loss\n",
        "\n",
        "# def numerical_gradient(x, y, W1, W2, b1, b2, eps):\n",
        "\n",
        "#     cincremental_der_W1 = funcion_objetivo(x, y, W1+eps, W2, b1, b2)\n",
        "#     cincremental_izq_W1 = funcion_objetivo(x, y, W1-eps, W2, b1, b2)\n",
        "#     derivada_W1 = (cincremental_der_W1-cincremental_izq_W1)/(2*eps)\n",
        "\n",
        "#     cincremental_der_W2 = funcion_objetivo(x, y, W1, W2+eps, b1, b2)\n",
        "#     cincremental_izq_W2 = funcion_objetivo(x, y, W1, W2-eps, b1, b2)\n",
        "#     derivada_W2 = (cincremental_der_W2-cincremental_izq_W2)/(2*eps)\n",
        "\n",
        "#     cicremental_der_b1 = funcion_objetivo(x, y, W1, W2, b1 + eps, b2)\n",
        "#     cicremental_izq_b1 = funcion_objetivo(x, y, W1, W2, b1 - eps, b2)\n",
        "#     derivada_b1 = (cicremental_der_b1 - cicremental_izq_b1)/(2*eps)\n",
        "\n",
        "#     cicremental_der_b2 = funcion_objetivo(x, y, W1, W2, b1, b2 + eps)\n",
        "#     cicremental_izq_b2 = funcion_objetivo(x, y, W1, W2, b1, b2 - eps)\n",
        "#     derivada_b2 = (cicremental_der_b2 - cicremental_izq_b2)/(2*eps)\n",
        "\n",
        "#     gradiente = np.zeros((4,1))\n",
        "#     gradiente[0][0] = derivada_W1\n",
        "#     gradiente[1][0] = derivada_W2\n",
        "#     gradiente[2][0] = derivada_b1\n",
        "#     gradiente[3][0] = derivada_b2\n",
        "    \n",
        "#     return gradiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "rJRtIYxMvhgo"
      },
      "outputs": [],
      "source": [
        "#funcion fit y loop de entrenamiento\n",
        "def fit(x, y, W1, W2, b1, b2, learning_rate, epochs):\n",
        "    eps = 1e-3\n",
        "    loss_accum = []\n",
        "    j = 0\n",
        "    gradw1 = 0\n",
        "    gradw2 = 0\n",
        "    gradb1 = 0\n",
        "    gradb2 = 0\n",
        "    for i in range(epochs):\n",
        "        aux_loss = 0\n",
        "        for j in range(x.shape[0]):\n",
        "            x_aux = np.array([x[j,:]])\n",
        "            objective_value = funcion_objetivo(x_aux, y[j], W1, W2, b1, b2)\n",
        "            aux_loss = aux_loss + objective_value\n",
        "\n",
        "            gradiente = numerical_gradient(x_aux, y[j], W1, W2, b1, b2, eps)\n",
        "            gradw1 = gradw1 + gradiente[0]\n",
        "            gradw2 = gradw2 + gradiente[1]\n",
        "            gradb1 = gradb1 + gradiente[2]\n",
        "            gradb2 = gradb2 + gradiente[3]\n",
        "\n",
        "        gradw1 = gradw1/x.shape[0]\n",
        "        gradw2 = gradw2/x.shape[0]\n",
        "        gradb1 = gradb1/x.shape[0]\n",
        "        gradb2 = gradb2/x.shape[0]\n",
        "\n",
        "        W1 = W1 - learning_rate*gradw1\n",
        "        W2 = W2 - learning_rate*gradw2\n",
        "        b1 = b1 - learning_rate*gradb1\n",
        "        b2 = b2 - learning_rate*gradb2\n",
        "\n",
        "        loss_accum.append(aux_loss/x.shape[0])\n",
        "\n",
        "    theta = [W1, W2, b1, b2]\n",
        "    return theta, loss_accum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "#funcion fit y loop de entrenamiento\n",
        "\n",
        "def fit_2(x, y, W1, W2, b1, b2, learning_rate, epochs):\n",
        "    eps = 1e-3\n",
        "    loss_accum = []\n",
        "    j = 0\n",
        "    grad_w1 = np.zeros(W1.shape)\n",
        "    grad_w2 = np.zeros(W2.shape)\n",
        "    grad_b1 = np.zeros(b1.shape)\n",
        "    grad_b2 = np.zeros(b2.shape)\n",
        "    for i in range(epochs):\n",
        "        aux_loss = 0\n",
        "        for j in range(x.shape[0]):\n",
        "            x_aux = np.array([x[j,:]])\n",
        "\n",
        "            objective_value = funcion_objetivo(x_aux, y[j], W1, W2, b1, b2)\n",
        "\n",
        "            aux_loss = aux_loss + objective_value\n",
        "\n",
        "            gradiente = numerical_gradient(x_aux, y[j], W1, W2, b1, b2, eps)\n",
        "            grad_w1 = grad_w1 + gradiente[0]\n",
        "            grad_w2 = grad_w2 + gradiente[1]\n",
        "            grad_b1 = grad_b1 + gradiente[2]\n",
        "            grad_b2 = grad_b2 + gradiente[3]\n",
        "\n",
        "        loss_accum.append(aux_loss/x.shape[0])\n",
        "\n",
        "        grad_w1 = grad_w1 / x.shape[0]\n",
        "        grad_w2 = grad_w2 / x.shape[0]\n",
        "        grad_b1 = grad_b1 / x.shape[0]\n",
        "        grad_b2 = grad_b2 / x.shape[0]\n",
        "\n",
        "        W1 = W1 - learning_rate * grad_w1\n",
        "        W2 = W2 - learning_rate * grad_w2\n",
        "        b1 = b1 - learning_rate * grad_b1\n",
        "        b2 = b2 - learning_rate * grad_b2\n",
        "\n",
        "    theta = [W1, W2, b1, b2]\n",
        "    return theta, loss_accum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "IS4sKd_Hvhgo"
      },
      "outputs": [],
      "source": [
        "def predict(x, W1, W2, b1, b2):\n",
        "    y = forward(W1, W2, b1, b2, x)\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalizar_x(x):\n",
        "    medias = x.mean()\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i] = x[i] - medias\n",
        "    return x  \n",
        "\n",
        "def normalizar_y(y):\n",
        "    media = y.mean()\n",
        "    for i in range(y.shape[0]):\n",
        "        y[i] = y[i] - media\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6683.652326260032 -  27.3 = 6656.352326260032\n",
            "5264.678545964278 -  42.0 = 5222.678545964278\n",
            "5734.217810743808 -  37.5 = 5696.717810743808\n",
            "5388.832143114676 -  49.8 = 5339.032143114676\n",
            "5285.070141063453 -  26.9 = 5258.170141063453\n",
            "8988.199495362713 -  18.6 = 8969.599495362712\n",
            "5936.6827497154945 -  37.7 = 5898.982749715495\n",
            "5199.545911388926 -  33.1 = 5166.445911388925\n",
            "5214.58077957634 -  42.5 = 5172.08077957634\n",
            "6641.056800293488 -  31.3 = 6609.756800293488\n",
            "5491.521699566861 -  38.1 = 5453.42169956686\n",
            "5081.228582195139 -  62.1 = 5019.128582195139\n",
            "5740.282973501894 -  36.7 = 5703.582973501894\n",
            "6439.3254738322885 -  23.6 = 6415.725473832288\n",
            "8988.805585573218 -  19.2 = 8969.605585573217\n",
            "6116.134876182886 -  12.8 = 6103.334876182886\n",
            "9294.957830123445 -  15.6 = 9279.357830123445\n",
            "5608.907622227123 -  39.6 = 5569.307622227123\n",
            "5123.733654529128 -  38.4 = 5085.333654529129\n",
            "5984.145954569383 -  22.8 = 5961.345954569383\n",
            "5347.6523464403635 -  36.5 = 5311.1523464403635\n",
            "6787.217854459165 -  35.6 = 6751.617854459165\n",
            "5594.115980656365 -  30.9 = 5563.215980656365\n",
            "5273.642734956292 -  36.3 = 5237.342734956292\n",
            "5337.6539978566625 -  50.4 = 5287.253997856663\n",
            "5279.531064037586 -  42.9 = 5236.631064037586\n",
            "5732.134142331054 -  37.0 = 5695.134142331054\n",
            "5113.080492489766 -  53.5 = 5059.580492489766\n",
            "5561.546733130699 -  46.6 = 5514.946733130699\n",
            "7940.067046688112 -  41.2 = 7898.867046688112\n",
            "5195.281416146329 -  37.9 = 5157.38141614633\n",
            "6642.9028603892875 -  30.8 = 6612.102860389287\n",
            "11156.360384558984 -  11.2 = 11145.160384558983\n",
            "5270.946000526355 -  53.7 = 5217.246000526356\n",
            "5123.733654529128 -  47.0 = 5076.733654529128\n",
            "5490.817446280726 -  42.3 = 5448.517446280725\n",
            "7083.774351384528 -  28.6 = 7055.174351384528\n",
            "7552.171312448004 -  25.7 = 7526.471312448004\n",
            "7054.313632258554 -  31.3 = 7023.013632258554\n",
            "6308.881297974033 -  30.1 = 6278.781297974033\n",
            "5388.501912835407 -  60.7 = 5327.801912835407\n",
            "5221.653464578001 -  45.3 = 5176.353464578001\n",
            "5349.448628278418 -  44.9 = 5304.548628278419\n",
            "5209.073484481307 -  45.1 = 5163.9734844813065\n",
            "7299.304123360065 -  24.7 = 7274.604123360065\n",
            "5112.427645352657 -  47.1 = 5065.327645352657\n",
            "5295.553430042988 -  63.3 = 5232.253430042988\n",
            "5940.4000494931925 -  40.0 = 5900.4000494931925\n",
            "5135.796992153611 -  48.0 = 5087.796992153611\n",
            "5609.9062150922355 -  33.1 = 5576.806215092235\n",
            "7162.252269550228 -  29.5 = 7132.752269550228\n",
            "6724.609912170297 -  24.8 = 6699.809912170297\n",
            "6750.948195370717 -  20.9 = 6730.048195370718\n",
            "5355.262074664015 -  43.1 = 5312.162074664015\n",
            "7088.889695696922 -  22.8 = 7066.089695696922\n",
            "5298.618292730126 -  42.1 = 5256.518292730126\n",
            "5321.99097779403 -  51.7 = 5270.29097779403\n",
            "5177.294397537021 -  41.5 = 5135.794397537021\n",
            "5280.8216831381105 -  52.2 = 5228.621683138111\n",
            "5394.924951284969 -  49.5 = 5345.424951284969\n",
            "6117.152321273558 -  23.8 = 6093.352321273558\n",
            "6647.297689638248 -  30.5 = 6616.797689638248\n",
            "5075.183084444313 -  56.8 = 5018.383084444313\n",
            "5585.803129184053 -  37.4 = 5548.403129184054\n",
            "5303.403860308615 -  69.7 = 5233.703860308615\n",
            "5299.91949265315 -  53.3 = 5246.61949265315\n",
            "5154.8064300579035 -  47.3 = 5107.506430057903\n",
            "8357.767616934434 -  29.3 = 8328.467616934435\n",
            "5503.2454949688845 -  40.3 = 5462.945494968884\n",
            "8864.755175624477 -  12.9 = 8851.855175624478\n",
            "5108.243151241233 -  46.6 = 5061.643151241233\n",
            "5195.68177086462 -  55.3 = 5140.38177086462\n",
            "7012.963319031921 -  25.6 = 6987.363319031921\n",
            "7154.293611170081 -  27.3 = 7126.993611170081\n",
            "5145.778421172113 -  67.7 = 5078.078421172113\n",
            "5388.209181051225 -  38.6 = 5349.609181051224\n",
            "6856.799697675059 -  31.3 = 6825.499697675059\n",
            "5447.713212633313 -  35.3 = 5412.4132126333125\n",
            "5939.388046431326 -  40.3 = 5899.088046431326\n",
            "8934.1576895215 -  24.7 = 8909.4576895215\n",
            "5509.479866323898 -  42.5 = 5466.979866323898\n",
            "5891.194961527959 -  31.9 = 5859.2949615279595\n",
            "6126.801003418834 -  32.2 = 6094.601003418834\n",
            "6647.297689638248 -  23.0 = 6624.297689638248\n",
            "5182.931935686114 -  37.3 = 5145.631935686114\n",
            "5483.238231803858 -  35.5 = 5447.738231803858\n",
            "7079.645553843344 -  27.7 = 7051.945553843344\n",
            "5199.134440644708 -  28.5 = 5170.634440644708\n",
            "5182.062634590567 -  39.7 = 5142.362634590567\n",
            "5300.047324188853 -  41.2 = 5258.847324188853\n",
            "5149.909172452661 -  37.2 = 5112.709172452661\n",
            "5378.703205639375 -  40.5 = 5338.203205639375\n",
            "7298.0808271533415 -  22.3 = 7275.780827153341\n",
            "7081.727284991137 -  28.1 = 7053.627284991137\n",
            "8879.802642929453 -  15.4 = 8864.402642929454\n",
            "5113.074934596908 -  50.0 = 5063.074934596908\n",
            "5397.652917548743 -  40.6 = 5357.052917548743\n",
            "5124.350860525347 -  52.5 = 5071.850860525347\n",
            "5115.126729944711 -  63.9 = 5051.226729944711\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_excel(\"Real estate valuation data set.xlsx\")\n",
        "datos = df.to_numpy()\n",
        "\n",
        "X = datos[:100,[1,2,3,4,5,6]]\n",
        "Y = datos[:100,7]\n",
        "\n",
        "X_test = datos[315:, [1,2,3,4,5,6]]\n",
        "Y_test = datos[315:,7]\n",
        "\n",
        "# x_norm = normalizar_x(X)\n",
        "# y_norm = normalizar_y(Y)\n",
        "theta = fit(X, Y, W1, W2, b1, b2, 0.0005, 1000)[0]\n",
        "# print(fit(X, Y, W1, W2, b1, b2, 0.0005, 1000)[1])\n",
        "\n",
        "# x_test_norm = normalizar_x(X_test)\n",
        "# y_test_norm = normalizar_y(Y_test)\n",
        "\n",
        "# xt_test_norm = x_test_norm.transpose()\n",
        "\n",
        "Xt_test = X_test.transpose()\n",
        "\n",
        "predictions = []\n",
        "resta = []\n",
        "\n",
        "# for i in range(X_test.shape[0]): \n",
        "#     predictions.append(predict(xt_test_norm[:,i], theta[0], theta[1], theta[2], theta[3]))\n",
        "#     resta.append(predictions[i] - y_test_norm[i])\n",
        "#     print(predictions[i], \"- \", y_test_norm[i], \"=\", resta[i])\n",
        "\n",
        "for i in range(X_test.shape[0]): \n",
        "    predictions.append(predict(Xt_test[:,i], theta[0], theta[1], theta[2], theta[3]))\n",
        "    resta.append(predictions[i] - Y_test[i])\n",
        "    print(predictions[i], \"- \", Y_test[i], \"=\", resta[i])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "metodos",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
